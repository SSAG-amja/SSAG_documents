"""
ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì—:
pip install pandas openpyxl requests
xlsx,csv
"""

import pandas as pd
import json
import os
import requests
from io import StringIO
from collections import defaultdict
import sys 
from core.config import SOLAR_API_KEY

# -----------------------------
# 1. ì„¤ì • (ê¸°ì¡´ ìœ ì§€)
# -----------------------------

# [ 1. ì…ë ¥ ] ì²˜ë¦¬í•  ë°ì´í„° íŒŒì¼ ê²½ë¡œ (CSV, XLSX ì¤‘ í•˜ë‚˜)
try:
    file_path = sys.argv[1] 
except IndexError:
    # ì—ëŸ¬ ë©”ì‹œì§€ëŠ” stderrë¡œ ì¶œë ¥
    print("ì˜¤ë¥˜: ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œë¥¼ ëª…ë ¹ì¤„ ì¸ìë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.", file=sys.stderr)
    sys.exit(1)

# [ 2. ì¶œë ¥ ] ìµœì¢… ì²­í¬ íŒŒì¼ ê´€ë ¨ ë³€ìˆ˜ëŠ” ì œê±°
base_name = os.path.basename(file_path)
file_name_prefix = os.path.splitext(base_name)[0]


SOLAR_LLM_ENDPOINT = "https://api.upstage.ai/v1/chat/completions"
SOLAR_LLM_HEADERS = {
    "Authorization": f"Bearer {SOLAR_API_KEY}",
    "Content-Type": "application/json"
}

ROWS_PER_CHUNK = 5 # ìƒì„¸ ì²­í¬ë‹¹ ë¬¶ì„ í–‰ì˜ ê°œìˆ˜

# -----------------------------
# 2. LLM í”„ë¡¬í”„íŠ¸ ë° í˜¸ì¶œ í•¨ìˆ˜ (ê¸°ì¡´ ìœ ì§€)
# -----------------------------

PROMPT_DATA_SUMMARY = """
ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒì˜ ë©”íƒ€ë°ì´í„°ì™€ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŒŒì¼ ì „ì²´ì˜ ë‚´ìš©ê³¼ ëª©ì ì„ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.

[íŒŒì¼ ë©”íƒ€ë°ì´í„°]
- íŒŒì¼ ì œëª©: {FILE_TITLE}
- ì—´ ì´ë¦„ ëª©ë¡: {COLUMN_NAMES}

[ë°ì´í„° ìƒ˜í”Œ (í—¤ë” í¬í•¨)]
{DATA_SAMPLE}
"""

def call_solar_llm_for_data_summary(file_name_prefix, column_names_str, data_sample_text):
    """
    Solar LLMì„ í˜¸ì¶œí•˜ì—¬ ë°ì´í„° íŒŒì¼ì˜ ì „ì²´ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.
    """
    try:
        print(f"    > Solar LLM í˜¸ì¶œ ì¤‘... (ë°ì´í„° ìš”ì•½)", file=sys.stderr)
        formatted_prompt = PROMPT_DATA_SUMMARY.format(
            FILE_TITLE=file_name_prefix,
            COLUMN_NAMES=column_names_str,
            DATA_SAMPLE=data_sample_text
        )
        
        payload = {
            "model": "solar-pro2",
            "messages": [{"role": "user", "content": formatted_prompt}]
        }
        
        # API í˜¸ì¶œ
        response = requests.post(SOLAR_LLM_ENDPOINT, headers=SOLAR_LLM_HEADERS, json=payload)
        response.raise_for_status() 
        
        return response.json()['choices'][0]['message']['content']
        
    except Exception as e:
        print(f"  > [LLM Error] Solar LLM ìš”ì•½ í˜¸ì¶œ ì‹¤íŒ¨: {e}", file=sys.stderr)
        return f"[LLM ì˜¤ë¥˜: ë°ì´í„° ìš”ì•½ ì‹¤íŒ¨]"


# -----------------------------
# 3. ë°ì´í„° ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ (ìˆ˜ì •: summary í•„ë“œ ì¶”ê°€)
# -----------------------------

def process_data_file(input_file, doc_id): 
    
    file_extension = os.path.splitext(input_file)[1].lower()
    base_name = os.path.basename(input_file)
    file_name_prefix = os.path.splitext(base_name)[0]
    
    df = None
    final_chunks = []
    
    # 1. íŒŒì¼ ë¡œë“œ
    try:
        if file_extension == '.csv':
            df = pd.read_csv(input_file)
        elif file_extension in ['.xlsx', '.xls']:
            df = pd.read_excel(input_file, engine='openpyxl')
        else:
            print(f"ì˜¤ë¥˜: ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.", file=sys.stderr)
            return
    except Exception as e:
        print(f"ì˜¤ë¥˜: íŒŒì¼ì„ pandasë¡œ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. {e}", file=sys.stderr)
        return

    print(f"\n[ë°ì´í„° ì²˜ë¦¬] '{base_name}' ë¡œë“œ ì„±ê³µ. (ì´ {len(df)} í–‰)", file=sys.stderr)

    # 1-1. LLMì—ê²Œ ì „ë‹¬í•  ë©”íƒ€ë°ì´í„° ì¤€ë¹„ (ì—´ ì´ë¦„ ì¶”ì¶œ)
    column_names = df.columns.tolist()
    column_names_str = ", ".join(column_names)
    print(f"  > ì¶”ì¶œëœ ì—´ ì´ë¦„: {column_names_str}", file=sys.stderr)


    # --- Layer 1: ìš”ì•½ ì²­í¬ (Chunk 0) ---
    
    # 2. ìƒ˜í”Œ ì¶”ì¶œ ë° CSV ë³€í™˜
    sample_df = df.head(ROWS_PER_CHUNK)
    csv_buffer = StringIO()
    sample_df.to_csv(csv_buffer, index=False)
    data_sample_text = csv_buffer.getvalue()

    # 3. LLM ìš”ì•½ í˜¸ì¶œ
    llm_summary_text = call_solar_llm_for_data_summary(file_name_prefix, column_names_str, data_sample_text)
    
    # 4. Chunk 0 (ìš”ì•½) ìµœì¢… ì €ì¥ (summary í•„ë“œ ì¶”ê°€)
    final_chunks.append({
        "doc_id": doc_id, 
        "page": 1, 
        "chunk_in_page": 0, 
        "text_for_embedding": f"íŒŒì¼ ì œëª©: {file_name_prefix}\n\n[ë°ì´í„° ì „ì²´ ìš”ì•½]\n{llm_summary_text}",
        "summary": llm_summary_text # <--- ğŸ’¡ summary í•„ë“œ ì¶”ê°€ (ìš”ì•½ ì²­í¬) ğŸ’¡
    })
    print(f"[Layer 1] ìš”ì•½ ì²­í¬ (Chunk 0) ìƒì„± ì™„ë£Œ.", file=sys.stderr)

    # --- Layer 2: ìƒì„¸ ë¸”ë¡ ì²­í¬ (Chunk 1+) ---

    num_rows = len(df)
    
    # 5. 5í–‰ ë‹¨ìœ„(ROWS_PER_CHUNK)ë¡œ ë°˜ë³µí•˜ë©° ë¸”ë¡ ì²­í¬ ìƒì„±
    for i in range(0, num_rows, ROWS_PER_CHUNK):
        chunk_df = df.iloc[i:i + ROWS_PER_CHUNK]
        chunk_index = i // ROWS_PER_CHUNK + 1 
        
        # 6. ë¸”ë¡ ë°ì´í„°ë¥¼ CSV í…ìŠ¤íŠ¸ë¡œ ì§ë ¬í™”
        csv_buffer = StringIO()
        
        # ì²« ë²ˆì§¸ ìƒì„¸ ì²­í¬(Chunk 1)ì—ë§Œ í—¤ë”ë¥¼ í¬í•¨
        include_header = (i == 0) 
        
        chunk_df.to_csv(csv_buffer, index=False, header=include_header)
        data_block_text = csv_buffer.getvalue().strip()
        
        # 7. ìµœì¢… í…ìŠ¤íŠ¸ í¬ë§·
        final_text_to_embed = f"íŒŒì¼ ì œëª©: {file_name_prefix}\n\n[ë°ì´í„° ë¸”ë¡ {chunk_index} (í–‰ {i+1}~{min(i+ROWS_PER_CHUNK, num_rows)})]\n{data_block_text}"
        
        # 8. Chunk 1+ (ìƒì„¸) ìµœì¢… ì €ì¥ (summary í•„ë“œ ì¶”ê°€)
        final_chunks.append({
            "doc_id": doc_id,
            "page": 1, 
            "chunk_in_page": chunk_index,
            "text_for_embedding": final_text_to_embed,
            "summary": llm_summary_text # <--- ğŸ’¡ summary í•„ë“œ ì¶”ê°€ (ìƒì„¸ ì²­í¬) ğŸ’¡
        })
    
    print(f"[Layer 2] ìƒì„¸ ë¸”ë¡ ì²­í¬ ({len(final_chunks) - 1}ê°œ) ìƒì„± ì™„ë£Œ.", file=sys.stderr)
    
    # <--- í•µì‹¬ ìˆ˜ì •: ìµœì¢… ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¥¼ JSON ë¬¸ìì—´ë¡œ stdoutì— ì¶œë ¥
    print(json.dumps(final_chunks, ensure_ascii=False)) 
    
    print(f"\n[ìµœì¢…] ì´ {len(final_chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ.", file=sys.stderr)


# -----------------------------
# 4. ì‹¤í–‰ (ê¸°ì¡´ ìœ ì§€)
# -----------------------------
if __name__ == "__main__":
    try:
        if not os.path.exists(file_path):
            print(f"ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}", file=sys.stderr)
        else:
            # doc_idë¥¼ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¡œ ì„¤ì • (ê³ ìœ ì„± ë³´ì¥)
            absolute_path = os.path.abspath(file_path)
            
            # ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ ì‹¤í–‰
            process_data_file(
                input_file=file_path,
                doc_id=absolute_path 
            )
            print("\n--- ì „ì²´ íŒŒì´í”„ë¼ì¸ ì„±ê³µ ---", file=sys.stderr)
            
    except Exception as e:
        print(f"\n--- íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ---", file=sys.stderr)
        print(e, file=sys.stderr)
        sys.exit(1)