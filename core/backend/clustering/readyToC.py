import numpy as np
import json
import os
import sys
import pandas as pd
from qdrant_client import QdrantClient # ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ë¡œì§ ì¬ì‚¬ìš©ì„ ìœ„í•´ í•„ìš”
import hdbscan # <--- í´ëŸ¬ìŠ¤í„°ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬
from core.config import QDRANT_URL, COLLECTION_NAME, QDRANT_API_KEY

# --- ë¡œì»¬ íŒŒì¼ ì„¤ì • (í˜„ì¬ ì‹¤í–‰ ë””ë ‰í† ë¦¬ì— ìˆë‹¤ê³  ê°€ì •) ---
VECTORS_FILE = "qdrant_vectors.npy"
PAYLOADS_FILE = "qdrant_payloads.json"
# ----------------------------------------------------


# ------------------------------------------------------
# 1. Qdrant ë°ì´í„° Fetch ë° Load í•¨ìˆ˜ (ì´ì „ ìŠ¤í¬ë¦½íŠ¸ì˜ í†µí•©)
# ------------------------------------------------------

def fetch_all_vectors_from_qdrant():
    """Qdrantì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ë¡œì»¬ì— ìºì‹œí•©ë‹ˆë‹¤."""
    
    if os.path.exists(VECTORS_FILE) and os.path.exists(PAYLOADS_FILE):
        print(f"[ì •ë³´] ë¡œì»¬ ìºì‹œ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë¶„ì„ì„ ë°”ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        return True
    
    try:
        qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
        if not qdrant_client.collection_exists(collection_name=COLLECTION_NAME):
             print(f"[ì˜¤ë¥˜] ì»¬ë ‰ì…˜ '{COLLECTION_NAME}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
             return False
        
        print(f"[ì‹œì‘] ì»¬ë ‰ì…˜ '{COLLECTION_NAME}'ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹œì‘. (ìµœì´ˆ ë‹¤ìš´ë¡œë“œ)")
        all_vectors = []
        all_payloads = []
        next_offset = None
        
        while True:
            scroll_response, current_offset = qdrant_client.scroll(
                collection_name=COLLECTION_NAME, limit=1000, offset=next_offset,
                with_vectors=True, with_payload=True
            )
            for point in scroll_response:
                all_vectors.append(point.vector)
                payload_data = point.payload.copy()
                payload_data['point_id'] = point.id 
                all_payloads.append(payload_data)
            
            next_offset = current_offset
            if next_offset is None:
                break
        
        if not all_vectors:
            print("[ê²½ê³ ] ì»¬ë ‰ì…˜ì— ì €ì¥ëœ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
            return False

        vectors_array = np.array(all_vectors, dtype=np.float32)
        
        np.save(VECTORS_FILE, vectors_array)
        with open(PAYLOADS_FILE, 'w', encoding='utf-8') as f:
            json.dump(all_payloads, f, ensure_ascii=False, indent=2)
            
        print(f"[ì™„ë£Œ] ì´ {len(vectors_array)}ê°œ ë²¡í„°ì™€ í˜ì´ë¡œë“œ ì €ì¥ ì™„ë£Œ. (í´ëŸ¬ìŠ¤í„°ë§ ì¤€ë¹„ ì™„ë£Œ)")
        return True

    except Exception as e:
        print(f"[ì˜¤ë¥˜] Qdrant ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}", file=sys.stderr)
        return False

def load_data_for_clustering():
    """ë¡œì»¬ì— ì €ì¥ëœ ë²¡í„°ì™€ í˜ì´ë¡œë“œë¥¼ ë©”ëª¨ë¦¬ë¡œ ë¡œë“œí•©ë‹ˆë‹¤."""
    
    if not os.path.exists(VECTORS_FILE) or not os.path.exists(PAYLOADS_FILE):
        return None, None
        
    vectors = np.load(VECTORS_FILE)
    with open(PAYLOADS_FILE, 'r', encoding='utf-8') as f:
        payloads = json.load(f)
        
    return vectors, payloads


# ------------------------------------------------------
# 2. HDBSCAN í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰ ë° ë¶„ì„
# ------------------------------------------------------

def run_clustering_analysis(vectors, payloads):
    """HDBSCAN í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    print(f"\n[ë¶„ì„] HDBSCAN í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘...", file=sys.stderr)
    
    # --- [ì¤‘ìš”] HDBSCAN í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ---
    # min_cluster_size: ìµœì†Œí•œ ì´ ìˆ˜ ì´ìƒì˜ í¬ì¸íŠ¸ê°€ ëª¨ì—¬ì•¼ í´ëŸ¬ìŠ¤í„°ë¡œ ì¸ì •ë©ë‹ˆë‹¤.
    # í´ëŸ¬ìŠ¤í„°ì˜ 'ë°€ë„' ì •ì˜ì— ë”°ë¼ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤. ë„ˆë¬´ í¬ë©´ í´ëŸ¬ìŠ¤í„°ê°€ ì ê²Œ ë‚˜ì˜µë‹ˆë‹¤.
    clusterer = hdbscan.HDBSCAN(
        min_cluster_size=3, 
        min_samples=3, 
        metric='euclidean', # ì„ë² ë”© ë²¡í„°ì— í”íˆ ì‚¬ìš©ë˜ëŠ” ê±°ë¦¬ ì¸¡ì •ë²•
    )
    
    # í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
    clusterer.fit(vectors)
    labels = clusterer.labels_
    
    unique_labels = set(labels)
    # ë…¸ì´ì¦ˆ(-1)ë¥¼ ì œì™¸í•œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ ê³„ì‚°
    num_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)
    num_noise = list(labels).count(-1)
    
    print(f"[ì™„ë£Œ] ì´ {num_clusters}ê°œ í´ëŸ¬ìŠ¤í„° ìƒì„±. ë…¸ì´ì¦ˆ í¬ì¸íŠ¸: {num_noise}ê°œ", file=sys.stderr)

    # 3. ê²°ê³¼ ë§¤í•‘ ë° ë¶„ì„ (Payload ì‚¬ìš©)
    df = pd.DataFrame(payloads)
    df['cluster_label'] = labels
    
    # 4. í´ëŸ¬ìŠ¤í„°ë³„ íŒŒì¼ ê¸°ì—¬ë„ ë¶„ì„
    # doc_id (íŒŒì¼ ê²½ë¡œ)ì—ì„œ íŒŒì¼ ì´ë¦„ë§Œ ì¶”ì¶œí•˜ê³ , í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ê³ ìœ í•œ íŒŒì¼ ëª©ë¡ì„ ìƒì„±
    cluster_summary = df.groupby('cluster_label')['doc_id'].agg(
        lambda x: pd.Series([os.path.basename(p) for p in x.unique()]).tolist()
    ).reset_index()
    
    # 5. ë…¸ì´ì¦ˆë¥¼ ì œì™¸í•œ í´ëŸ¬ìŠ¤í„°ë§Œ ë¶„ì„
    meaningful_clusters = cluster_summary[cluster_summary['cluster_label'] != -1]
    
    print("\n" + "="*50)
    print("      í´ëŸ¬ìŠ¤í„°ë³„ íŒŒì¼ ê¸°ì—¬ë„ ë° í¬ê¸° ìš”ì•½")
    print("="*50)
    
    for index, row in meaningful_clusters.iterrows():
        cluster_id = row['cluster_label']
        contributing_files = row['doc_id']
        cluster_size = len(df[df['cluster_label'] == cluster_id])
        
        # í´ëŸ¬ìŠ¤í„°ì˜ ëŒ€í‘œ í…ìŠ¤íŠ¸ (ì²« ë²ˆì§¸ ì²­í¬)
        sample_text = df[df['cluster_label'] == cluster_id]['text_for_embedding'].iloc[0][:100].replace('\n', ' ') + "..."

        print(f"## ğŸ† í´ëŸ¬ìŠ¤í„° {cluster_id} (í¬ê¸°: {cluster_size}ê°œ ì²­í¬)")
        print(f"  - ëŒ€í‘œ ë‚´ìš© (ìƒ˜í”Œ): {sample_text}")
        print(f"  - ê¸°ì—¬ íŒŒì¼ ({len(contributing_files)}ê°œ): {', '.join(contributing_files)}")
        print("-" * 20)

    print(f"\n[ë…¸ì´ì¦ˆ] ë…¸ì´ì¦ˆ í¬ì¸íŠ¸ (-1 ë¼ë²¨) ì´ {num_noise}ê°œ (í´ëŸ¬ìŠ¤í„°ë§ ë˜ì§€ ì•ŠìŒ)")
    print("="*50)


if __name__ == "__main__":
    if fetch_all_vectors_from_qdrant():
        vectors, payloads = load_data_for_clustering()
        
        if vectors is not None and len(vectors) > 0:
            print(f"\n--- [í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰] ---")
            run_clustering_analysis(vectors, payloads)
        else:
            print("í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", file=sys.stderr)